+--
utilizando o curl para requisições http
-X POST : verbo da requisição
-v      : resposta verbosa com headers e body
-H      : cabeçalhos
-d      : corpo

curl http://localhost:3000/pagamentos/pagamento
    -X POST
    -v
    -H "Content-type: application/json"
    -d '{
        "forma_de_pagamento": "payfast",
        "valor": "10.87",
        "moeda": "BRL",
        "descricao": "descrição do pagamento"
    }'

curl http://localhost:3000/pagamentos/pagamento
    -X POST
    -v
    -H "Content-type: application/json"
    -d @files/pagamento.json

copy/paste cmd
literal:
    curl http://localhost:3000/pagamentos/pagamento -X POST -v -H "Content-type: application/json" -d "{\"forma_de_pagamento\": \"payfast\", \"valor\": \"10.87\", \"moeda\": \"BRL\", \"descricao\": \"descrição do pagamento\"}"
file:
    curl http://localhost:3000/pagamentos/pagamento -X POST -v -H "Content-type: application/json" -d @files/pagamento.json
=--

+--
status code HTTP importante para api REST:
100 Continue: o servidor recebeu a solicitação e o cliente pode continuar a comunicação.
200 Ok: tudo ocorreu como esperado.
201 Created: um novo recurso foi criado no servidor.
301 Moved: a url solicitada foi movida.
400 Bad Request: problemas na requisição do cliente.
404 Not Found: a url solicitada não foi encontrada.
500 Internal Server Error: algo inesperado aconteceu do lado do servidor
=--

+--
A sigla REST vêm de Representational State Transfer e surgiu da tese de doutorado de Roy Fielding, descrevendo as ideias que levaram à criação do protocolo HTTP. A Web é o maior exemplo de uso de uma arquitetura REST, onde os verbos são as operações disponíveis no protocolo (GET, POST, DELETE, PUT, OPTION...), os recursos são identificados pelas URLs e as representações podem ser definidas com o uso de Mime Types(texto, XML, JSON e outros).
=--

+--
Métodos HTTP
GET: retorna uma representação do recurso
POST: cria ou altera o recurso
PUT: cria ou altera o recurso
DELETE: remove o recurso
outras menos comuns, como HEAD e OPTIONS

Os quatro principais verbos do protocolo HTTP são comumente associados às operações de CRUD em sistemas Restful (POST -> INSERT, GET -> SELECT, PUT -> UPDATE, DELETE -> DELETE). Há uma grande discussão dos motivos pelos quais usamos POST para criação (INSERT) e PUT para alteração (UPDATE). A razão principal é que o protocolo HTTP especifica que a operação PUT deve ser idempotente, já POST não.

Idempotência e SAFE
Operações idempotentes são operações que podem ser chamadas uma ou mais vezes, sempre com o mesmo resultado final.

Uma operação é chamada SAFE se ela não altera nenhuma representação.

Idempotência e SAFE são propriedades das operações e fundamentais para a escalabilidade da Web.
=--

+--
Hipermídia
Os recursos serão apresentados por meio de representações. Seguindo os princípios RESTful, representações devem ser interligadas umas com a outras. Isso é chamado hipermídia e conhecido na Web através de hyperlinks. No nosso exemplo, a representações de um livro poderia conter a URI dos autores. Como resultado disso, é possível navegar entre os recursos.

Mais sobre hipermídia no blog da Caelum:

http://blog.caelum.com.br/hipermidia-e-contratos-dinamicos-menor-acoplamento/

RESTful
Qualquer sistema que aplique as ideias do estilo arquitetural REST, pode ser chamado de RESTful. Existe uma intensa discussão na comunidade sobre quando um sistema pode ser considerado RESTful ou não, porém, na maioria dos casos, basta apenas implantar uma parte do REST (em especial pensar em recursos, verbos fixos e ligações entre apresentações) para ser chamado de RESTfull
=--

+--
Coreografia de serviços com HATEOAS
Um pagamento nasce a partir de uma transação com estado CRIADO e pode ser CONFIRMADO ou CANCELADO pelo cliente. Confirmar representa um "próximo passo" na vida do pagamento e pode ou não ser seguido pelo cliente. A ideia principal é que um recurso informe ao cliente quais os próximos passos ou relacionamentos, e atrás de cada relacionamento há um serviço transformador de dados.

Uma vez criado um pagamento vamos então receber os dados dele e também os relacionamentos:
{
    "id":3,"status":"CRIADO","valor":29.9,
    "links":[
        {"rel":"confirmar","uri":"/pagamentos/pagamento/3","method":"PUT"},
        {"rel":"cancelar","uri":"/pagamentos/pagamento/3","method":"DELETE"}
    ]
}
No entanto, um pagamento no estado CONFIRMADO, podemos pedir apenas informações sobre o pagamento. Assim, a apresentação do recurso, além dos dados, também leva sempre as informações sobre o que é permitido executar:
{
    "id":3,"status":"CONFIRMADO","valor":29.9,
    "links":[
        {"rel":"self","uri":"/pagamentos/pagamento/3","method":"GET"}
    ]
}
Essa forma de juntar os dados às ações é conhecida como hypermedia e é a essência do HATEOAS - Hypermedia as the Engine of Application State.

Para que seja aplicado o HATEOAS ao PayFast basta que cada rota passe a adicionar no body do seu response as informações com os próximos links possíveis a serem seguidos após a requisição que foi feita.
=--

+--
O restify simplifica bastante a vida para consumir serviços REST, mas lembre sempre que serviços REST nada mais são do que integração via HTTP, então qualquer chamada via request HTTP normal também deveria funcionar normalmente.
=--

+--
Streaming de dados
Muitas das apis assíncronas utilizadas no Node.js trabalham utilizando o chamado buffer mode. Em uma operação de entrada de dados o buffer mode faz com que todos os dados oriundos da requisição fiquem armazenados em um buffer. Para que então seja passado para algum callback tão somente todo o recurso tenha sido lido.

Esse tipo de estratégia não é muito interessante para o Node.js, visto que ele é pensando para trabalhar com operações de I/O e faz isso muito bem, mas quando a necessidade é ficar manipulando muito recurso na memória, que é o que fazem os buffers, ele passa a perder bastante performance.

A solução ideal para resolver essa questão seria conseguir ir processando os dados conforme eles fossem chegando, ao invés de ter que esperar a leitura do dado por inteiro. É exatamente isso que a api de Streams do Node.js possibilita ao programador.

Existem diversas vantagens em se utilizar essa api sempre que possível. Veja as principais:

Eficiência espacial
Primeiro de tudo, os Streams nos permitem fazer coisas que não seriam possíveis somente bufferizando dados processando-os todos de uma vez.

Por exemplo: imagine que a aplicação precise ler arquivos muito grandes da ordem dos mega ou até gigabytes. Agora imagine que a aplicação precise ler alguns desses arquivos de forma concorrente. Claramente utilizar uma api que retorna um grande buffer quando o arquivo está completamente lido não é uma boa ideia. A aplicação iria fatalmente cair por falta de memória.

Além disso, os buffers na V8, a runtime sobre a qual o Node.js roda, suporta como tamanho máximo para buffers um número que sequer chega a 1 GB de memória. Ou seja a aplicação esbarraria em uma limitação do próprio ambiente antes mesmo de chegar ao limite físico de memória.

Utilizar Streams nessa situação reduz em muito o uso de memória da aplicação e faz com que ela rode de uma maneira mais suave.

Eficiência temporal
Vamos considerar agora o caso de uma aplicação que precisa comprimir um arquivo e após fazer o seu upload para um servidor HTTP remoto. Este servidor então recebe o arquivo, descompacta e salva-o em seu sistema de arquivos.

Se o cliente tiver sido implementando utilizando uma api com buffers, o upload só iria iniciar uma vez que o arquivo inteiro tenha sido lido e compactado. Do outro lado e descompressão também só iria ter início uma vez que o arquivo inteiro tenha sido recebido.

Uma melhor solução seria implementar a mesma funcionalidade com streams. Do lado do cliente, os streams permitem que aplicação vá lendo e enviando os arquivos conforme eles forem sendo lidos do sistema de arquivos. E do lado do servidor ela permite que seja feita a descompactação de cada pedaço de arquivo, conforme eles vão sendo recebidos do cliente remoto. Esses pedaços costumam ser chamados de chunks.

É bem fácil perceber que a abordagem com streams gera um ganho de tempo gigantesco e que escala bem melhor.
=--

+--
O Memcached é definido como um sistema de caching de objetos em memória grátis, open source, distribuído e de alta performance, genérico por natureza, mas com uma forte intenção de acelerar o processamento de aplicações web dinâmicas, aliviando a carga de acessos ao banco de dados. Exatamente o objetivo que tínhamos ao pensar em implementar uma política de cache no PayFast.

Ele funciona baseado em um esquema chave-valor que armazena pequenos pedaços de dados de qualquer tipo desejado (string, objetos...) em memória. Podendo esses dados ser oriundos de consultas à banco de dados, à outras APIs ou até mesmo do carregamento de páginas.

Ele é um framework simples, porém bastante poderoso. Fácil de instalar, fazer deploy e de desenvolver sobre ele, por ter um design simples. Além de prover APIs para diversas linguagens de programação.

A instalação do Memcached é muito simples. Uma forma bem padrão de fazê-la é baixar a última versão direto do site oficial, descompactar e instalar:

    wget http://memcached.org/latest
    tar -zxvf memcached-1.x.x.tar.gz
    cd memcached-1.x.x
    ./configure && make && make test && sudo make install

Este exemplo mostra a instalação feita diretamente no terminal.

Após instalado, basta executar um comando no próprio terminal para que ele suba e fique pronto para receber conexões:

    memcached -vv

// -vv  indica modo verboso

objeto memcached:
    retries:    10, o número de retentativas feitas por request.
    retry:      10000, o tempo entre a falha de um servidor e uma tentativa de colocá-lo de volta em serviço.
    remove:     true, autoriza a remoção automática de servidores mortos do pool.
=--

+--
Utilizando logs na aplicação
Um dos pontos mais críticos de uma aplicação é quando se precisa identificar aquele famoso "erro que só acontece em produção". Nessa situação o programador não tem como debugar o código e muitas vezes não consegue reproduzir a situação em um ambiente de testes porque não tem como saber de fato qual foi o cenário ocorrido.

Quando isso acontece é muito importante que se tenha disponível toda informação possível sobre aquela execução. E a melhor maneira de conseguir isso é através de Logs. Pois ele são o rastro da execução da aplicação e podem ser tão detalhados quanto o programador desejar.

Logs simples com Winston
Uma api bem simples, mas bastante eficaz para o uso de logs é a winston. Ela foi projetada para ser uma API de logs simples e universal com suporte para múltiplas camadas de logs. É possível que cada instância do winston tenha múltiplas camadas de logs e diferentes níveis em cada uma dessas camadas.

Ela também desacopla bastante a sua implementação interna de escrita dos logs das interfaces que são expostas para o programador. Isso facilita muito a vida do programador e é algo que muitas APIs de log acabam não fazendo.

var winston = require('winston');
Com objeto em mãos é possível criar um nova instância de logger com as camadas desejadas:

    var logger = new winston.Logger({
      transports: [
        new winston.transports.File({
          level: "info",
          filename: "logs/payfast.log",
          maxsize: 1048576,
          maxFiles: 10,
          colorize: false
        });
      ]
    });
Cada camada é representada por um transport e você pode ver que a criação do objeto recebe um array deles. Então de fato é possível ter várias camadas. Ou vários transports.

Dentro de cada transport são definidas as características específicas de cada camada, como onde o log será escrito por exemplo: se será num arquivo, num banco de dados, no console, etc. O primeiro requisito definido no exemplo acima foi que o log deveria ser escrito em um arquivo:

    new winston.transports.File({ ...
Dentro desse objeto agora são passadas as informações referentes à escrita nesse arquivo:

level: "info": indica o nível do log.
filename: "logs/payfast.log": o arquivo onde o log será escrito.
maxsize: 1048576: o tamanho máximo a que pode chegar o arquivo de log, para que comece a ser rotacionado.
maxFiles: 10: a quantidade máxima de arquivos que devem ser mantidos para essa camada de log.
colorize: false: se o log deve usar cores ou não.
Existem ainda diversas outras possíveis configurações e você pode encontrar a relação completa no GitHub do projeto: https://github.com/winstonjs/winston

Para finalmente escrever o log agora basta utilizar o objeto que contem a camada criada e invocar um dos métodos de escrita:

    logger.log('info', 'Log forçando o nível info via parâmetro na função log().');
    logger.info('Log forçando o nível info via invocação direta função info()');
=--

+--
ogando as requisições com Morgan
Claro que a ideia principal do uso dos logs é que eles possam ficar localizados nas partes mais críticas dos sistemas para que se tenha as informações detalhadas de cada execução. Uma forma de fazer isso, seria escrevendo uma camada do winston para cada rota criada no sistema.

Mas essa opção obviamente seria mais trabalhosa que o necessário e teríamos que espalhar código repetido e difícil de manter por todo o projeto. Uma maneira mais elegante de fazer essa implementação seria interceptando todas as requisições em um ponto único do código.

Como o express é quem coordena as requisições, o seu arquivo de configurações custom-express.js parece ser um forte candidato para receber este código. E de fato, já existe uma lib cujo objetivo é exatamente esse: o morgan, que é um middleware escritor de logs HTTP para Node.js.

Após instalado na aplicação via npm, o morgan precisa ser definido como um novo middleware do express. Essa implementação deve ser feita no custom-express.js. O primeiro passo é fazer o require da lib:

    ...
    var morgan = require('morgan');
    var logger = require('../persistencia/logger.js');

Um detalhe importante é que morgan é basicamente um middleware mesmo, ou seja, a especialidade dele é saber se integrar corretamente com o express. Mas ele não é um especialista em escrever os logs em si. Por esse motivo é que foi carregado também o arquivo persistencia/logger.js, que contém as implementação do winston. A ideia então é aproveitar aquilo que o winston faz de melhor para que seja aproveitado pelo morgan. Um belo exemplo de reuso de código.

Em seguida, deve ser feita de fato a adição do morgan como um novo middleware do express:

    ...
    module.exports = function() {
      var app = express();

      app.use(morgan("common", {
        stream: {
          write: function(message){
            logger.info(message)
          }
        }
      }));
    ...
Essa adição é feita invocando a função use a partir do objeto do express e dentro dessa invocação é passada como parâmetro a chama ao objeto do morgan: morgan(). Essa chamada também recebe alguns parâmetros: o primeiro deles indica o formato do log e o segundo é um json com configurações mais específicas.

O formato do log pode ser um formato já pré-definido ou algum que tenha sido criado. Nesse caso foi utilizado o "commom". Este é um formato pré-definido que significa a saída de log padrão no nível comum segundo o Padrão da Apache. Em outras palavras, um log com os seguintes itens para cada requisição:

    :remote-addr - :remote-user [:date[clf]] ":method :url HTTP/:http-version" :status :res[content-length]
No segundo parâmetro, o json, foi definido que o log será escrito via stream e que o código que deve ser executado no momento que o morgan interceptar o request para fazer uma escrita deve ser a função que foi definida no atributo write:

    write: function(message){
      logger.info(message)
    }
Essa função usa objeto logger para escrever uma mensagem. Esse objeto é o qe foi definido com o winston e carregado para este arquivo no início dessa seção. A message que chega como parâmetro é passada pelo próprio express e seu formato foi definido pelo atributo "commons" conforme já demonstrado.
=--